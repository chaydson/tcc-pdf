\chapter[Planejamento do Estudo de Caso]{Planejamento do Estudo de Caso}
\label{chap:planejamento-estudo-caso}

Neste capítulo é apresentado o planejamento do estudo de caso, que será conduzido na segunda etapa do trabalho, onde são estabelecidos os conceitos e definições relacionados a esse método. 

\section{Definição} 

\citeonline{yin2015estudo} define o estudo de caso como uma investigação empírica que analisa um determinado fenômeno da atualidade em seu contexto real, ou seja, o pesquisador se insere no ambiente cotidiano onde o objeto de estudo está sendo executado. Essa abordagem é particularmente relevante para a Engenharia de Software, pois frequentemente os fenômenos analisados nessa área são complexos e interligados, o que dificulta analisá-los isoladamente do seu ambiente de execução \cite{Runeson2009}.

Ainda de acordo com \citeonline{yin2015estudo}, o estudo de caso é flexível e interativo. Isso significa que a estrutura do estudo pode se adaptar no decorrer da pesquisa, pois, o pesquisador, ao realizar as interações de coleta e análise dos dados, pode vir a perceber características do caso que não foram identificadas a priori.

Ademais, visando assegurar o rigor e a confiabilidade da investigação, os estudos de caso devem coletar dados de múltiplas fontes. Dessa forma, ao verificar que conclusões obtidas através de dados obtidos em diferentes locais apontam para o mesmo resultado, aumenta-se a robustez e confiabilidade dos resultados, pois esse processo de triangulação diminui a probabilidade de erro ou viés, além de fornecer uma visão mais ampla sobre o caso \cite{yin2015estudo}.

Também é necessário determinar se o estudo será holístico ou incorporado \cite{yin2015estudo}. Os estudos de caso holísticos analisam o caso como um todo, ou seja, o fenômeno é visto como um sistema único e integrado, portanto, o pesquisador obtém uma visão ampla e geral do caso. Já os estudos incorporados, tem como principal característica o aprofundamento em múltiplas unidades de análise dentro de um mesmo caso, permitindo uma análise mais aprofundada.

Para além disso, \cite{Runeson2009} explicita a necessidade de considerar as ameaças a validade do estudo desde o início da pesquisa, pois ignorar tais fatores interfere na confiabilidade dos resultados. A primeira ameaça definida pelo autor está relacionada à validade do constructo, que representa em qual extensão as medidas operacionais realmente representam o que o pesquisador tem em mente e o que está sendo investigado de acordo com as perguntas de pesquisa. Já a ameaça a validade interna, refere-se ao risco de existir um fator não mapeado pelo pesquisador que cause interferência na relação causal entre os fatores selecionados.
As ameaças externas, por outro lado, estão relacionadas a capacidade de generalização do estudo, ou seja, deseja-se que os achados do estudo tenham relevância para casos com características semelhantes. Por fim, a confiabilidade refere-se ao grau em que os dados e a análise dependem de pesquisadores específicos, isto é, se outro pesquisador conduzisse o mesmo estudo, o resultado deveria ser o mesmo.

\section{Objetivo}

Segundo \citeonline{Siavvas2021431}, o desenvolvimento de software seguro é pautado na medição da qualidade da segurança de software, pois assim, é possível avaliar o nível da segurança do produto e conseguir traçar metas para guiar os processos de melhoria contínua do sistema. Porém, por diversas vezes são utilizados critérios de avaliação subjetivos ou que não possuem a devida validação, o que pode acarretar catastofrés relacionadas a segurança do produto.
Situação essa que se agrava ao se tratar de práticas emergentes na indústria, como DevSecOps, que apesar de seu destaque no desenvolvimento ágil, por muitas vezes, carece de avaliação por metodologias apropriadas.

Assim, o objetivo desse estudo consiste em investigar como as práticas DevSecOps afetam os aspectos relacionados a segurança de um projeto de software livre em desenvolvimento. Para tanto serão utilizados métodos, técnicas e ferramentas, observadas e propostos na literatura específica da área de segurança e em consonância com o estado da prática na indústria.

\section{Caso}
O objeto de estudo do trabalho é a plataforma Brasil Participativo. Ela se trata de uma plataforma digital de participação social de software livre desenvolvida pelo Governo Federal do Brasil, que tem como objetivo promover a interação entre cidadãos e o governo, permitindo que a população participe de consultas públicas, conferências, planos e enquetes sobre políticas públicas. O projeto é uma iniciativa da Secetraria-Geral da Presidência da República, desenvolvido pela Universidade de Brasília, hospedado pela Dataprev e tendo como base o Decidim \cite{BrasilParticipativo}.

O Brasil Participativo possibilitou que 1.619.015 pessoas de diversas regiões do país contribuíssem com ideias de impacto nacional de forma simples, segura e transparente. A plataforma conta com, aproximadamente, 9.200.013 acessos e um total de 47 processos desde o seu laçamento, o que evidencia o seu caráter fundamental na democracia brasileira ao promover a diversidade e inclusão no desenvolvimento de políticas públicas \cite{BrasilParticipativo}.

O Decidim é um framework democrático participativo genérico baseado em Ruby on Rails. Trata-se de um software livre desenvolvido pelo governo de Barcelona para promover a participação cidadã e a democracia participativa. Ele permite que qualquer organização faça uma adaptação de seus componentes para a própia realidade, desse modo, tornou-se uma referência em tecnologia cívica. \cite{Decidim}

Esse projeto foi escolhido por ser um software livre que conta com equipes de segurança e desenvolvimento acessíveis e ativas, o que facilita a comunicação e a colaboração durante o estudo de caso. Além disso, o laboratório responsável pelo projeto possui um ambiente de desenvolvimento ágil, cultura DevSecOps e entregas em andamento, o que é fundamental para a avaliação das práticas implementadas. Por fim, o software é de grande relevância social, o que reforça a importância de garantir sua segurança e confiabilidade.

\section{Trabalhos Relacionados}

Alguns trabalhos obtidos por meio da revisão da literatura foram utilizados como referência para a realização desta pesquisa. Esses artigos foram selecionados, pois abordam os temas pertinentes e correlatos, para o planejamento e execução da pesquisa deste estudo de caso. 

O estudo realizado por \citeonline{Siavvas2021431} foi o estudo central para a elaboração da monografia. Sua relevância se dá, pois ele apresenta um modelo hierárquico de avaliação de segurança que quantifica a segurança interna do software com base em alertas de análise estática (SAST) e métricas de software.
O autor demonstrou que é possível avaliar a segurança de forma confiável e quantiativa usando modelos de qualidade e análise estática.

O trabalho de \cite{Zhang2024160317}, apresenta doze métricas quantitativas de DevSecOps especificamente projetadas para microsserviços web baseados em nuvem. O foco é avaliar a qualidade, segurança e eficiência operacional, com o intuito de auxiliar na tomada de decisões informadas e na melhoria contínua.

A revisão sistemática feita por \citeonline{Rajapakse2022}, identifica os desafios e soluções na adoção do DevSecOps, incluindo seleção de ferramentas, avaliação contínua de segurança e o equilíbrio entre velocidade e segurança

\citeonline{Saeed2025139} aborda técnicas para integrar a segurança no ciclo de desenvolvimento de software, enfatizando a necessidade de uma abordagem colaborativa e ferramentas automatizadas para análise de ameaças e testes de segurança.

\section{Questão de Pesquisa}
\label{sec:questoes-caso}

Similar ao processo realizado no planejamento da revisão da literatura, a metodologia GQM \citeonline{Basili1994} foi usada para definição das perguntas específicas, derivadas da pergunta principal e suas respectivas métricas para conduzir o estudo, de modo a não desviar do objetivo principal e estabelecer a avaliação quantitativa ou qualitativa, de cada uma das questões de pesquisa secundárias, que agora norteaiam o estudo de caso.


A \citeonline{ISO25010} define como confidencialidade, a capacidade do sistema de impedir o acesso não autorizado às informações, assim, impedindo que os dados privados sejam visíveis para quem não possui as permissões necessárias. Ela será uma a sub-característica de segurança analisadas neste estudo de caso, por meio da análise de vulnerabilidades detectadas no pipeline de CI/CD. Para corroborar com essa análise e fazer a triangularização da coleta de dados, uma avaliação qualitativa com os membros do time é necessária para observar os impactos dessas novas práticas no processo de desenvolvimento.

À vista disso, as seguintes perguntas específicas foram elaboradas:

\begin{itemize}
    \item Questão Específica 1: A aplicação de práticas DevSecOps permitiu identificar vulnerabilidades de segurança sob as perspectivas da qualidade interna e externa do produto?
    \begin{itemize}
        \item Métrica 1.1: Média de vulnerabilidades encontradas por ferramentas SAST, por nível de severidade, por merge.
        \item Métrica 1.2: Média de vulnerabilidades encontradas por ferramentas DAST, por nível de severidade, por merge.
        \item Métrica 1.3: Proporção de vulnerabilidades em bibliotecas encontradas por ferramentas SCA, por nível de severidade, por merge.
    \end{itemize}
    \item Questão Específica 2: A análise automática da segurança do pipeline e as métricas coletadas ajudaram na tomada de decisões relacionadas ao projeto?
    \begin{itemize}
        \item Métrica 2.1: Taxa de pipelines sinalizadas devido à descoberta de vulnerabilidades de criticidade média ou superior, por merge.
        \item Métrica 2.2: Feedback do time obtido por um questionário sobre os impactos das novas práticas.
    \end{itemize}
\end{itemize}


\section{Fonte de Dados}

Para coletar os dados necessários para a posterior avaliação das métricas são necessárias diferentes fontes de dados. Primeiramente, as ferramentas SAST e SCA são executadas diretamente no código-fonte. 
Outra fonte de dados é o sistema em uso, que será usado para a obtençao dos dados referentes às ferramentas DAST que analisam o software em execução.
Adiconalmente, o orquestrador de CI/CD atuará como fonte de dados para coletar os tentativas falhas de integração do código, evidênciando a identificação de falhas pelas ferramentas.

Por fim, a equipe técnica será a fonte de dados dos formulários de avaliação ao final do estudo de caso, permitindo a análise qualitativa e triangularização dos resultados.

\section{Unidades de Análise e Procedimentos}

Para atender à complexidade das questões de pesquisa deste trabalho, optou-se pelo método de estudo de caso incorporado ou embutido, fundamentado por \citeonline{yin2015estudo}. 
Esta abordagem foi escolhida, pois permite que o caso principal seja investigado por meio da análise aprofundada de múltiplas subunidades de análise. Especificamente, o estudo se debruça sobre diferentes faces do projeto, como
o impacto na qualidade da segurança interna e externa do produto, e a percepção da equipe sobre as mudanças implementadas. Ao examinar cada um desses componentes seguindo o protocolo de estudo de caso, é possível construir uma visão detalhada e triangulada que
fortalece a validade das conclusões e oferece uma resposta mais completa ao problema investigado.

Desse modo, a primeira unidade de análise é constituída pelo produto em si, ou seja, os artefatos da plataforma Brasil Participativo e seus componentes, como o código-fonte, as bibliotecas de terceiros e o sistema em execução. A coleta de dados para esta unidade é composta por uma análise quantitativa independente de artefatos de trabalho no código e suas bibliotecas, por meio de ferramentas SAST e SCA, além da análise do sistema em execução por ferramentas DAST.

A segunda unidade de análise é composta pelos processos adotadas pela equipe de desenvolvimento, incluindo a pipeline de CI/CD e as práticas DevSecOps implementadas. O estudo visa investigar o efeito dessas práticas no fluxo de trabalho e tomada de decisões do time. Esta unidade terá como dados quantitativos as métricas coletadas do orquestrador de CI/CD, que indicam as entregas bloqueadas devido à detecção de vulnerabilidades críticas. 

Por último, a terceira unidade de análise envolve a equipe técnica responsável pelo desenvolvimento e manutenção do software, cuja percepção sobre as mudanças será avaliada por meio de um questionário. O objetivo é coletar o feedback da equipe sobre o impacto das práticas DevSecOps no processo de desenvolvimento, identificando benefícios, desafios e sugestões de melhoria. Esta unidade de análise fornecerá dados qualitativos que complementarão as análises quantitativas das outras unidades.

\section{Análise de Dados}

A análise dos dados quantitativos será fundamentada em estatísticas descritivas e em análise de tendência, visando avaliar a evolução da segurança da aplicação ao longo do tempo. Para as métricas de detecção de vulnerabilidades por ferramentas SAST e DAST, Métrica 1.1 e Métrica 1.2, adaptadas da métrica B.34 - Security Incidents Trend da norma \citeonline{ISO27004}, será calculado um indicador de tendência para permitir avaliar o volume de vulnerabilidades, por nível de severidade, a cada sprint.

O cálculo do indicador é obtido através da razão entre a média de vulnerabilidades das últimas duas sprints concluídas e a média das últimas seis sprints concluídas, sendo que, um valor inferior a 1.0 indica uma tendência de melhoria, entre 1.0 e 1.3 sinaliza uma tendência de estabilidade e superior a 1.3 indica uma piora significativa.

Para a Métrica 1.3, adaptada da métrica Shared or Unknown Library Ratio proposta por \citeonline{Zhang2024160317}, será calculada a proporção de bibliotecas com vulnerabilidades em relação ao total. Por sua vez, a Métrica 2.1, uma adaptação da métrica Change Fail Percentage elaborado pelo \citeonline{DORA2024}, será calculada pela taxa percentual de builds/deploys bloqueados por vulnerabilidades de criticidade média ou superior. O acompanhamento destas métricas será realizado continuamente, visando observar tendência ao longo do tempo.

Para a análise de frequência de respostas do questionário, Métrica 2.2, a frequência de cada das respostas de cada pergunta será registrada, de modo a possibilitar o cálculo da moda, pois ao ter a opinião da maioria dos participantes sobre o tópico solicitado será possível obter a percepção geral do impacto das atividades realizadas.

\section{Instrumentação}

A instrumentação se refere às ferramentas que serão utilizadas para a realização do estudo de caso, aqui estão definidas as ferramentas usadas para a análise da segurança do sistema, controle de implementação do código, versionamento do código da pipeline feita e coleta de informações da equipe.

O SonarQube \footnote{\href{https://www.sonarsource.com/products/sonarqube/}{www.sonarsource.com/products/sonarqube/}} é uma ferramenta de open-source de avalição da qualidade e segurança do código-fonte. Ele realiza análise estática para detectar bugs, vulnerabilidades e code smells em várias linguagens. Ele fará parte das ferramentas white-box integradas ao pipeline realizando a análise estática de segurança de aplicação (SAST). 


O Trivy \footnote{\href{https://trivy.dev/latest/}{https://trivy.dev/latest/}}
 é um scanner de segurança de código aberto. Ele é utilizado na análise de composição de software, verificando as bibliotecas de terceiros do projeto, garantindo que componentes externos ao projeto não insiram vulnerabilidades no sistemas. Além disso, ele é capaz de buscar vulnerabilidades em containeres e configurações de infraestrutura como código. Ele complementará o SonarQube como ferramenta white-box.

O Zed Attach Proxy-ZAP \footnote{\href{https://www.zaproxy.org/}{https://www.zaproxy.org/}} foi desenvolvido para encontrar problemas de segurança em aplicações web em execução. Ele será empregado para realizar a Análise Dinâmica de Segurança de Aplicação (DAST) em um ambiente de testes.

O GitLab CI/CD \footnote{\href{https://docs.gitlab.com/install/}{https://docs.gitlab.com/install/}} é uma ferramenta integrada ao GitLab que permite a automação das etapas do ciclo de vida do software, através dele que as ferramentas de segurança serão executadas automaticamente e ele servirá para bloquear o build/deploy caso vulnerabilidades sejam encontradas.

O Git \footnote{\href{https://git-scm.com/downloads}{https://git-scm.com/downloads}} é um sistema de controle de versão e o GitHub \footnote{\href{https://github.com/}{https://github.com/}} é uma plataforma de hospedagem de código-fonte para controle de versão com Git. Eles serão utilizados para o versionamento e armazenamento dos artefatos por este estudo de caso.

O Google Forms\footnote{\href{https://docs.google.com/forms/u/0/}{https://docs.google.com/forms/u/0/}} permite a criação rápida e fácil de formulários online, além de permitir a gestão e análise dos resultados. Ele será utilizado para a aplicação do questionário que coleta os dados qualitativos da equipe.


\section{Ameaças à Validade do Estudo}

Conforme destacado por \citeonline{Runeson2009}, é essencial considerar as ameaças à validade desde o início da pesquisa para garantir a confiabilidade dos resultados. Nesta seção, são identificadas as principais ameaças à validade deste estudo de caso e as estratégias adotadas para sua mitigação.

Há quatro preocupações centrais para avaliar a qualidade dos resultados obtidos em uma pesquisa. São conhecidas como testes às ameaças: de constructo; interna, externa e de confiabilidade.  Ao conduzir estudos de caso, podemos aplicar diversas estratégias para atender a esses testes. Contudo, nem todas essas estratégias são usadas apenas na fase de planejamento formal. Algumas delas são aplicadas durante a coleta e análise dos dados, ou mesmo nas etapas de estruturação da pesquisa \cite{yin2015estudo}.

Com o objetivo de gerenciar os riscos inerentes ao estudo de caso proposto, planejamos tratar algumas das principais ameaças a validade do estudo:

\subsection{Ameaças à Validade do Constructo}

A ameça a validade do constructo diz respeito a capacidade do pesquisador intrepretar as alterações e variações, observadas na execução do estudo de caso de forma a garantir fidedignamente a representação da realidade. Em outras palavras, o pesquisador precisa garantir que os eventos observados \textit{in loco}, realmente refletem o fenômeno de forma inequívoca, ou se aconteceram apenas com base nas impressões do pesquisador.

Para realizar esse teste, o pesquisador o pesquisador precisa assegurar o cumprir duas etapas:

\begin{enumerate}
  \item selecionar os tipos específicos de mudanças que devem ser estudadas;
  \item demonstrar que as medidas operacionais selecionadas  fornecem uma percepção quantitativa dessas mudanças e que, são corretas para os conceitos que estão sob estudo.;
\end{enumerate}


Dessa maneira, as medidas selecionadas podem não capturar completamente os aspectos de segurança que se pretende avaliar. Para mitigar essa ameaça, foram selecionadas medidas baseadas em modelos e normas de referência na literatura, como a \citeonline{ISO27004} e estudos que apresentam evidências experimentais dos seus "achados" como discuto por \citeonline{Zhang2024160317}.

Além disso, para garantir esse alinhamento, foi adotada a abordagem GQM detalhada na subseção \ref{qp_principal}. Com isso, há uma questão de pesquisa principal, norteadora de todo o trabalho e há outras questões específicas, secundárias, da revisão estruturada da literatura e do estudo de caso. Essas questões possuem suas respectivas métricas que que por sua vez, auxiliam a quantificar ou qualificar as percepções da segurança, por meio os dados coletados e analisados.

\subsection{Ameaças à Validade Interna}

As ameaças a validade interna tratam das relações de causalidade. Portanto, analisa a relação de causa e efeito entre as variáveis observadas.

Por se tratar de um estudo do tipo exploratório, que procura observar e compreender um fenômeno específico, ocorrendo em seu ambiente real, o foco é a perpeção de todo o contexto. Por isso,  esse teste não se aplica a esta pesquisa. \cite{yin2015estudo}. 

\subsection{Ameaças à Validade Externa}

A validade externa, por sua vez, refere-se ao grau de generalização dos resultados observados \cite{yin2015estudo}.


Estudos de caso costumam ser criticados em virtude do baixo poder de generalização dos seus resultados, principalmente em comparação a análises quantitativas. No entanto, essa analogia, que considera amostra e população é equivocada quando se fala em estudos de caso.

Análises puramente quantitativas,  utilizam a generalização estatística, onde uma amostra, se bem representada, pode ser facilmente estendida a uma população maior.

Já nos estudos de caso, o objetivo do pesquisador é usar um conjunto específico de resultados para corroborar ou expandir uma teoria mais abrangente, em vez de aplicá-los diretamente a um universo estatístico.

Este estudo está limitado a um caso único, o projeto Brasil Participativo, que possui características específicas que podem não ser compatíveis ou aplicáveis em outros sistemas de software ou contextos. Embora as conclusões sejam específicas deste caso, como forma de mitigar essa ameaça, toda a descrição metodológica e documentação necessária para a compreensão das singularidades do caso Brasil Participativo estarão disponíveis em reposítórios públicos. Dessa forma, outros pesquisadores podem analisar a viabilidade da replicação dos resultados em seus contextos específicos.


\subsection{Ameaças à Confiabilidade}

Por fim, a ameaça a confiabilidade refere-se a capacidade de repodução dos procedimentos por outros pesquisadores. Com isso,  verifica-se se os resultados observados são consistentes, caso a reprodução obtenha os mesmos resultados \cite{yin2015estudo} \cite{Wohlin:2012:ESE:2349018}.

Variações na forma como os dados são coletados e analisados podem afetar os resultados. Para mitigar essa ameaça, serão fornecidas informações detalhadas sobre o produto, o processo, o contexto, o time de desenvolvimento, o conjunto de dados coletados e analisados, além do código-fonte e scripts utilizados na construção do tratamento proposto. Todas essas informações ficarão disponíveis em repositórios públicos. Serão estabelecidos procedimentos claros e, quando possível, automatizados, para a coleta de dados, minimizando a intervenção manual e sistematizando a análise. Além disso, todas as ferramentas utilizadas na instrumentação são produtos de software de código-fonte livre ou aberto.

